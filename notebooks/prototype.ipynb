{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # AI Personal Trainer — Demo notebook (Ollama + MediaPipe)\n",
    "# Requisiti: Python 3.10+, Ollama in esecuzione su localhost:11434, webcam opzionale.\n",
    "# Questo notebook supporta anche un file video o una simulazione senza camera."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T12:29:32.326214Z",
     "start_time": "2025-09-08T12:29:32.323249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Cell 1: Config & imports ---\n",
    "import os, time, json, math, re\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional, Tuple, Any\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "import mediapipe as mp\n",
    "\n",
    "# Ollama\n",
    "OLLAMA_URL = os.environ.get(\"OLLAMA_URL\", \"http://localhost:11434/api/generate\")\n",
    "OLLAMA_MODEL = os.environ.get(\"OLLAMA_MODEL\", \"llama3.1\")\n",
    "\n",
    "DISPLAY_SCALE = 0.9\n",
    "\n",
    "user_profile = {\n",
    "    \"name\": \"Alex\",\n",
    "    \"age\": 32,\n",
    "    \"sex\": \"M\",\n",
    "    \"height_cm\": 178,\n",
    "    \"weight_kg\": 76,\n",
    "    \"level\": \"intermediate\",\n",
    "    \"goals\": [\"ricomposizione corporea\", \"forza\", \"resistenza\"],\n",
    "    \"preferences\": {\n",
    "        \"tone\": \"motivational_friendly\",\n",
    "        \"cue_style\": \"visual_plus_short_verbal\",\n",
    "        \"language\": \"it-IT\"\n",
    "    },\n",
    "    \"equipment\": {\"dumbbells\": True, \"mini_barbell\": True, \"bands\": True, \"mat\": True},\n",
    "    \"constraints\": {\"lower_back_sensitivity\": False, \"shoulder_limitations\": False, \"knee_limitations\": False}\n",
    "}\n"
   ],
   "id": "4dd6befa532e0491",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:22:16.768039Z",
     "start_time": "2025-09-08T13:22:16.753256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Cell 2: Pose + feature utils (riuso delle tue funzioni) ---\n",
    "class PoseEstimator:\n",
    "    def __init__(self, static_image_mode=False, model_complexity=1, enable_segmentation=False):\n",
    "        self.mp_pose = mp.solutions.pose\n",
    "        self.pose = self.mp_pose.Pose(\n",
    "            static_image_mode=static_image_mode,\n",
    "            model_complexity=model_complexity,\n",
    "            enable_segmentation=enable_segmentation,\n",
    "            smooth_landmarks=True,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "        self.drawing = mp.solutions.drawing_utils\n",
    "        self.drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "    def process(self, frame_bgr):\n",
    "        frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "        return self.pose.process(frame_rgb)\n",
    "\n",
    "    def draw_landmarks(self, frame_bgr, landmarks, visibility_th=0.5, highlight: Dict[int, Tuple[int,int,int]]=None):\n",
    "        if landmarks is None:\n",
    "            return frame_bgr\n",
    "        image = frame_bgr.copy()\n",
    "        self.drawing.draw_landmarks(\n",
    "            image, landmarks, self.mp_pose.POSE_CONNECTIONS,\n",
    "            landmark_drawing_spec=self.drawing_styles.get_default_pose_landmarks_style()\n",
    "        )\n",
    "        if highlight:\n",
    "            h, w = image.shape[:2]\n",
    "            for idx, color in highlight.items():\n",
    "                lmk = landmarks.landmark[idx]\n",
    "                if lmk.visibility >= visibility_th:\n",
    "                    cx, cy = int(lmk.x*w), int(lmk.y*h)\n",
    "                    cv2.circle(image, (cx, cy), 8, color, -1)\n",
    "        return image\n",
    "\n",
    "POSE = mp.solutions.pose.PoseLandmark\n",
    "\n",
    "def _get_xy(landmarks, idx, frame_shape):\n",
    "    h, w = frame_shape[:2]\n",
    "    l = landmarks.landmark[idx]\n",
    "    return np.array([l.x*w, l.y*h], dtype=np.float32), float(l.visibility)\n",
    "\n",
    "def angle(a, b, c):\n",
    "    ab = a - b; cb = c - b\n",
    "    denom = (np.linalg.norm(ab)*np.linalg.norm(cb) + 1e-6)\n",
    "    cosang = np.clip(np.dot(ab, cb)/denom, -1.0, 1.0)\n",
    "    return math.degrees(math.acos(cosang))\n",
    "\n",
    "def knee_angle(landmarks, side:str, frame_shape):\n",
    "    hip,knee,ankle = (POSE.LEFT_HIP,POSE.LEFT_KNEE,POSE.LEFT_ANKLE) if side==\"left\" else (POSE.RIGHT_HIP,POSE.RIGHT_KNEE,POSE.RIGHT_ANKLE)\n",
    "    A,_=_get_xy(landmarks, hip, frame_shape); B,_=_get_xy(landmarks, knee, frame_shape); C,_=_get_xy(landmarks, ankle, frame_shape)\n",
    "    return angle(A,B,C)\n",
    "\n",
    "def hip_angle(landmarks, side:str, frame_shape):\n",
    "    shoulder,hip,knee = (POSE.LEFT_SHOULDER,POSE.LEFT_HIP,POSE.LEFT_KNEE) if side==\"left\" else (POSE.RIGHT_SHOULDER,POSE.RIGHT_HIP,POSE.RIGHT_KNEE)\n",
    "    A,_=_get_xy(landmarks, shoulder, frame_shape); B,_=_get_xy(landmarks, hip, frame_shape); C,_=_get_xy(landmarks, knee, frame_shape)\n",
    "    return angle(A,B,C)\n",
    "\n",
    "def elbow_angle(landmarks, side:str, frame_shape):\n",
    "    shoulder,elbow,wrist = (POSE.LEFT_SHOULDER,POSE.LEFT_ELBOW,POSE.LEFT_WRIST) if side==\"left\" else (POSE.RIGHT_SHOULDER,POSE.RIGHT_ELBOW,POSE.RIGHT_WRIST)\n",
    "    A,_=_get_xy(landmarks, shoulder, frame_shape); B,_=_get_xy(landmarks, elbow, frame_shape); C,_=_get_xy(landmarks, wrist, frame_shape)\n",
    "    return angle(A,B,C)\n",
    "\n",
    "def line_point_distance(p1, p2, p):  # distanza del punto p dalla retta p1-p2\n",
    "    # p1, p2, p sono np.array([x,y])\n",
    "    num = np.abs(np.cross(p2 - p1, p1 - p))\n",
    "    den = (np.linalg.norm(p2 - p1) + 1e-6)\n",
    "    return float(num / den)\n",
    "\n",
    "def pelvis_drop_norm(landmarks, frame_shape):\n",
    "    Lhip,_ = _get_xy(landmarks, POSE.LEFT_HIP, frame_shape)\n",
    "    Rhip,_ = _get_xy(landmarks, POSE.RIGHT_HIP, frame_shape)\n",
    "    hip_mid = (Lhip + Rhip) / 2\n",
    "    # normalizza su altezza \"corpo\" proxy (spalla->caviglia)\n",
    "    Lsh,_ = _get_xy(landmarks, POSE.LEFT_SHOULDER, frame_shape)\n",
    "    Lank,_ = _get_xy(landmarks, POSE.LEFT_ANKLE, frame_shape)\n",
    "    body_len = np.linalg.norm(Lsh - Lank) + 1e-6\n",
    "    return float((Lhip[1] - Rhip[1]) / body_len)  # positivo se anca sinistra \"più bassa\"\n",
    "\n",
    "def compute_features(landmarks, frame_shape) -> Dict[str,float]:\n",
    "    # base init per None\n",
    "    if landmarks is None:\n",
    "        keys = [\n",
    "            \"knee_ang\",\"hip_ang\",\"elbow_ang\",\"shoulder_ang\",\"ankle_ang\",\n",
    "            \"depth\",\"valgus_flag\",\"knee_valgus_score\",\n",
    "            \"left_knee_over_ankle\",\"right_knee_over_ankle\",\n",
    "            \"torso_tilt\",\"pelvis_drop_norm\",\"shoulder_hip_ankle_collinearity\",\n",
    "            \"arm_symmetry\",\"leg_symmetry\",\"stance_width\",\"grip_width\",\n",
    "            \"bar_vertical_disp\",\"shoulderY\",\"wristY\",\n",
    "            \"knee_to_chest_norm_L\",\"knee_to_chest_norm_R\",\n",
    "            \"crossbody_knee_wrist_prox_L\",\"crossbody_knee_wrist_prox_R\",\n",
    "            \"hands_to_feet_min_dist\",\"tuck_compactness\",\"arms_overhead\"\n",
    "        ]\n",
    "        return {k:0.0 for k in keys}\n",
    "\n",
    "    h, w = frame_shape[:2]\n",
    "\n",
    "    # --- ANGOLI MEDI (già noti + nuovi) ---\n",
    "    knee = (knee_angle(landmarks,\"left\",frame_shape)+knee_angle(landmarks,\"right\",frame_shape))/2\n",
    "    hipA = (hip_angle(landmarks,\"left\",frame_shape)+hip_angle(landmarks,\"right\",frame_shape))/2\n",
    "    elbow = (elbow_angle(landmarks,\"left\",frame_shape)+elbow_angle(landmarks,\"right\",frame_shape))/2\n",
    "    # shoulder/ankle aggiuntivi\n",
    "    def shoulder_angle(side):  # busto–spalla–gomito\n",
    "        hip, shoulder, elbow_j = ((POSE.LEFT_HIP, POSE.LEFT_SHOULDER, POSE.LEFT_ELBOW) if side==\"left\"\n",
    "                                  else (POSE.RIGHT_HIP, POSE.RIGHT_SHOULDER, POSE.RIGHT_ELBOW))\n",
    "        A,_ = _get_xy(landmarks, hip, frame_shape)\n",
    "        B,_ = _get_xy(landmarks, shoulder, frame_shape)\n",
    "        C,_ = _get_xy(landmarks, elbow_j, frame_shape)\n",
    "        return angle(A,B,C)\n",
    "    def ankle_angle(side):     # ginocchio–caviglia–punta\n",
    "        knee_j, ankle_j, foot_j = ((POSE.LEFT_KNEE, POSE.LEFT_ANKLE, POSE.LEFT_FOOT_INDEX) if side==\"left\"\n",
    "                                   else (POSE.RIGHT_KNEE, POSE.RIGHT_ANKLE, POSE.RIGHT_FOOT_INDEX))\n",
    "        A,_ = _get_xy(landmarks, knee_j, frame_shape)\n",
    "        B,_ = _get_xy(landmarks, ankle_j, frame_shape)\n",
    "        C,_ = _get_xy(landmarks, foot_j, frame_shape)\n",
    "        return angle(A,B,C)\n",
    "    shoulderA = (shoulder_angle(\"left\")+shoulder_angle(\"right\"))/2\n",
    "    ankleA = (ankle_angle(\"left\")+ankle_angle(\"right\"))/2\n",
    "\n",
    "    # --- PUNTI CHIAVE ---\n",
    "    Lhip,_ = _get_xy(landmarks, POSE.LEFT_HIP, frame_shape)\n",
    "    Rhip,_ = _get_xy(landmarks, POSE.RIGHT_HIP, frame_shape)\n",
    "    Lkne,_ = _get_xy(landmarks, POSE.LEFT_KNEE, frame_shape)\n",
    "    Rkne,_ = _get_xy(landmarks, POSE.RIGHT_KNEE, frame_shape)\n",
    "    Lank,_ = _get_xy(landmarks, POSE.LEFT_ANKLE, frame_shape)\n",
    "    Rank,_ = _get_xy(landmarks, POSE.RIGHT_ANKLE, frame_shape)\n",
    "    Lwri,_ = _get_xy(landmarks, POSE.LEFT_WRIST, frame_shape)\n",
    "    Rwri,_ = _get_xy(landmarks, POSE.RIGHT_WRIST, frame_shape)\n",
    "    Lsho,_ = _get_xy(landmarks, POSE.LEFT_SHOULDER, frame_shape)\n",
    "    Rsho,_ = _get_xy(landmarks, POSE.RIGHT_SHOULDER, frame_shape)\n",
    "\n",
    "    mid_sho = (Lsho + Rsho)/2\n",
    "    mid_hip = (Lhip + Rhip)/2\n",
    "    mid_ank = (Lank + Rank)/2\n",
    "\n",
    "    # --- PROFONDITÀ SQUAT ---\n",
    "    depth = float( ((Lhip[1]+Rhip[1])/2) - ((Lkne[1]+Rkne[1])/2) )\n",
    "\n",
    "    # --- VALGISMO NORMALIZZATO ---\n",
    "    hip_width = abs(Rhip[0] - Lhip[0]) + 1e-6\n",
    "    left_kot  = (Lkne[0] - Lank[0]) / hip_width\n",
    "    right_kot = (Rkne[0] - Rank[0]) / hip_width\n",
    "    knee_valgus_score = max(0.0, -left_kot) + max(0.0, right_kot)\n",
    "    valgus_flag = 1 if knee_valgus_score > 0.08 else 0  # soglia di esempio\n",
    "\n",
    "    # --- TORSO / COLLINEARITÀ PER PLANK ---\n",
    "    # torso_tilt: angolo rispetto verticale del vettore hip->shoulder (media L/R)\n",
    "    torso_vec = mid_sho - mid_hip\n",
    "    torso_tilt = math.degrees(math.atan2(torso_vec[0], torso_vec[1]))  # 0 = verticale\n",
    "\n",
    "    # distanza (normalizzata) dell'anca dalla retta spalla–caviglia (collinearity error)\n",
    "    sha = mid_sho; ank = mid_ank\n",
    "    hip_line_dist = line_point_distance(sha, ank, mid_hip)\n",
    "    norm_len = (np.linalg.norm(sha - ank) + 1e-6)\n",
    "    shoulder_hip_ankle_collinearity = float(hip_line_dist / norm_len)\n",
    "\n",
    "    # --- SIMMETRIE & LARGHEZZE ---\n",
    "    arm_symmetry = float(elbow_angle(landmarks,\"left\",frame_shape) - elbow_angle(landmarks,\"right\",frame_shape))\n",
    "    leg_symmetry = float(knee_angle(landmarks,\"left\",frame_shape)  - knee_angle(landmarks,\"right\",frame_shape))\n",
    "    stance_width = float(abs(Lank[0] - Rank[0]))\n",
    "    grip_width   = float(abs(Lwri[0] - Rwri[0]))\n",
    "\n",
    "    # --- ROM verticale (press/trazioni) ---\n",
    "    shoulderY = float((Lsho[1] + Rsho[1]) / 2)\n",
    "    wristY    = float((Lwri[1] + Rwri[1]) / 2)\n",
    "    bar_vertical_disp = float(shoulderY - wristY)\n",
    "\n",
    "    # --- MOUNTAIN CLIMBER: knee->chest & cross-body ---\n",
    "    # normalizzazione su lunghezza gamba (anca->caviglia)\n",
    "    leg_len = float(np.linalg.norm(mid_hip - mid_ank) + 1e-6)\n",
    "    knee_to_chest_norm_L = float(np.linalg.norm(Lkne - mid_sho) / leg_len)\n",
    "    knee_to_chest_norm_R = float(np.linalg.norm(Rkne - mid_sho) / leg_len)\n",
    "    # prossimità ginocchio-pols(o) opposto (più piccolo = più \"cross\")\n",
    "    crossbody_knee_wrist_prox_L = float(np.linalg.norm(Lkne - Rwri) / (norm_len + 1e-6))\n",
    "    crossbody_knee_wrist_prox_R = float(np.linalg.norm(Rkne - Lwri) / (norm_len + 1e-6))\n",
    "\n",
    "    # --- BURPEES: mani <-> piedi & tuck compactness & braccia sopra la testa ---\n",
    "    hands_to_feet_min_dist = float(min(\n",
    "        np.linalg.norm(Lwri - Lank), np.linalg.norm(Lwri - Rank),\n",
    "        np.linalg.norm(Rwri - Lank), np.linalg.norm(Rwri - Rank)\n",
    "    ) / (norm_len + 1e-6))\n",
    "    # tuck: ginocchia molto vicine al torace (valore piccolo = ottimo tuck)\n",
    "    tuck_compactness = float(min(knee_to_chest_norm_L, knee_to_chest_norm_R))\n",
    "    # braccia sopra la testa: polsi più in alto (y minore) delle spalle\n",
    "    arms_overhead = 1.0 if wristY < shoulderY - 10 else 0.0  # 10 px come margine\n",
    "\n",
    "    return {\n",
    "        \"knee_ang\":float(knee),\"hip_ang\":float(hipA),\"elbow_ang\":float(elbow),\n",
    "        \"shoulder_ang\":float(shoulderA),\"ankle_ang\":float(ankleA),\n",
    "        \"depth\":depth,\n",
    "        \"valgus_flag\":int(valgus_flag),\n",
    "        \"knee_valgus_score\":float(knee_valgus_score),\n",
    "        \"left_knee_over_ankle\":float(left_kot),\n",
    "        \"right_knee_over_ankle\":float(right_kot),\n",
    "        \"torso_tilt\":float(torso_tilt),\n",
    "        \"pelvis_drop_norm\":float(pelvis_drop_norm(landmarks, frame_shape)),\n",
    "        \"shoulder_hip_ankle_collinearity\":float(shoulder_hip_ankle_collinearity),\n",
    "        \"arm_symmetry\":arm_symmetry,\"leg_symmetry\":leg_symmetry,\n",
    "        \"stance_width\":stance_width,\"grip_width\":grip_width,\n",
    "        \"bar_vertical_disp\":bar_vertical_disp,\n",
    "        \"shoulderY\":shoulderY,\"wristY\":wristY,\n",
    "        \"knee_to_chest_norm_L\":knee_to_chest_norm_L,\n",
    "        \"knee_to_chest_norm_R\":knee_to_chest_norm_R,\n",
    "        \"crossbody_knee_wrist_prox_L\":crossbody_knee_wrist_prox_L,\n",
    "        \"crossbody_knee_wrist_prox_R\":crossbody_knee_wrist_prox_R,\n",
    "        \"hands_to_feet_min_dist\":hands_to_feet_min_dist,\n",
    "        \"tuck_compactness\":tuck_compactness,\n",
    "        \"arms_overhead\":arms_overhead\n",
    "    }"
   ],
   "id": "fbf19e18cdb17684",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:22:19.822952Z",
     "start_time": "2025-09-08T13:22:19.819924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2, numpy as np, os, requests\n",
    "\n",
    "def safe_imread(path_or_url:str, fallback_size=(480,640)):\n",
    "    \"\"\"\n",
    "    - Se path_or_url è un file esistente -> lo carica.\n",
    "    - Altrimenti tenta di scaricarlo come URL e salvarlo in 'test_input.jpg'.\n",
    "    - Se fallisce, ritorna un frame nero (placeholder).\n",
    "    \"\"\"\n",
    "    img = None\n",
    "    if os.path.exists(path_or_url):\n",
    "        img = cv2.imread(path_or_url)\n",
    "    else:\n",
    "        try:\n",
    "            r = requests.get(path_or_url, timeout=10)\n",
    "            r.raise_for_status()\n",
    "            with open(\"test_input.jpg\", \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "            img = cv2.imread(\"test_input.jpg\")\n",
    "        except Exception:\n",
    "            img = None\n",
    "\n",
    "    if img is None:\n",
    "        img = np.zeros((fallback_size[0], fallback_size[1], 3), dtype=np.uint8)\n",
    "        print(\"⚠️ Immagine non trovata/non scaricata: uso placeholder nero.\")\n",
    "    return img"
   ],
   "id": "3c64bfcfcfd7ec60",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:22:21.639202Z",
     "start_time": "2025-09-08T13:22:21.634044Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Opzione A: file locale\n",
    "img = safe_imread(\"../data/image/squat.jpg\")\n",
    "\n",
    "# Opzione B: URL (incolla un link a una foto intera di una persona)\n",
    "# img = safe_imread(\"https://.../una_foto_intera.jpg\")"
   ],
   "id": "330b37214c24ebe4",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:22:23.653306Z",
     "start_time": "2025-09-08T13:22:23.575002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Richiede: PoseEstimator definita nelle celle precedenti\n",
    "pe = PoseEstimator(static_image_mode=True)\n",
    "\n",
    "frame = img  # usa l'immagine caricata con safe_imread\n",
    "res = pe.process(frame)\n",
    "\n",
    "if res and res.pose_landmarks:\n",
    "    out = pe.draw_landmarks(frame, res.pose_landmarks)\n",
    "    cv2.imwrite(\"keypoints_preview.jpg\", out)\n",
    "    print(\"✅ Keypoints disegnati. File: keypoints_preview.jpg\")\n",
    "    print(\"Landmarks rilevati:\", len(res.pose_landmarks.landmark))  # atteso 33\n",
    "else:\n",
    "    print(\"❌ Nessun corpo rilevato: prova un'altra foto (intera, ben illuminata).\")\n"
   ],
   "id": "d59471ea2e0c21d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Keypoints disegnati. File: keypoints_preview.jpg\n",
      "Landmarks rilevati: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1757337743.582121 6326649 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M4 Max\n",
      "W0000 00:00:1757337743.630497 6605810 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1757337743.637897 6605823 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:22:26.529053Z",
     "start_time": "2025-09-08T13:22:26.525648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Richiede: compute_features(...) definita nelle celle precedenti\n",
    "if res and res.pose_landmarks:\n",
    "    feats = compute_features(res.pose_landmarks, frame.shape)\n",
    "    # stampa ordinata e leggibile\n",
    "    nice = {k: (round(v,2) if isinstance(v, float) else v) for k,v in feats.items()}\n",
    "    print(\"📊 Features:\", nice)\n",
    "else:\n",
    "    print(\"❌ Niente features: nessun landmark trovato.\")"
   ],
   "id": "d849e456b34fa4d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Features: {'knee_ang': 154.94, 'hip_ang': 147.23, 'elbow_ang': 111.72, 'shoulder_ang': 68.83, 'ankle_ang': 164.2, 'depth': -29.81, 'valgus_flag': 1, 'knee_valgus_score': 0.19, 'left_knee_over_ankle': -0.19, 'right_knee_over_ankle': -0.13, 'torso_tilt': -177.26, 'pelvis_drop_norm': -0.02, 'shoulder_hip_ankle_collinearity': 0.02, 'arm_symmetry': -72.29, 'leg_symmetry': 40.81, 'stance_width': 75.45, 'grip_width': 143.59, 'bar_vertical_disp': 0.64, 'shoulderY': 150.37, 'wristY': 149.73, 'knee_to_chest_norm_L': 1.13, 'knee_to_chest_norm_R': 1.17, 'crossbody_knee_wrist_prox_L': 0.91, 'crossbody_knee_wrist_prox_R': 0.73, 'hands_to_feet_min_dist': 1.0, 'tuck_compactness': 1.13, 'arms_overhead': 0.0}\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:33:07.582565Z",
     "start_time": "2025-09-08T13:33:07.579508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dizionario: nome feature -> descrizione da passare al LLM\n",
    "FEATURE_DOCS = {\n",
    "  \"knee_ang\": \"Gradi al ginocchio (anca-ginocchio-caviglia). 180=esteso, ~60-100 in accosciata.\",\n",
    "  \"hip_ang\": \"Gradi all’anca (spalla-anca-ginocchio). Più basso = più flessione d’anca.\",\n",
    "  \"elbow_ang\": \"Gradi al gomito (spalla-gomito-polso). 180=braccio esteso.\",\n",
    "  \"shoulder_ang\": \"Gradi alla spalla (anca-spalla-gomito). Usa per press/alzate.\",\n",
    "  \"ankle_ang\": \"Gradi alla caviglia (ginocchio-caviglia-punta). Usa per squat/affondi.\",\n",
    "  \"depth\": \"Differenza verticale anca-ginocchio (px). Negativo = anca più bassa del ginocchio.\",\n",
    "  \"valgus_flag\": \"1 se le ginocchia collassano verso il centro (proxy 2D normalizzata), altrimenti 0.\",\n",
    "  \"knee_valgus_score\": \"Entità del collasso mediale ginocchia (normalizzato su larghezza bacino).\",\n",
    "  \"left_knee_over_ankle\": \"Offset orizzontale ginocchio-sx vs caviglia-sx (normalizzato bacino). Negativo = verso il centro.\",\n",
    "  \"right_knee_over_ankle\": \"Offset orizzontale ginocchio-dx vs caviglia-dx (normalizzato bacino). Positivo = verso il centro.\",\n",
    "  \"torso_tilt\": \"Inclinazione busto rispetto alla verticale (°). 0≈verticale; >0=più inclinato.\",\n",
    "  \"pelvis_drop_norm\": \"Differenza altezza anche L-R normalizzata (asimmetria bacino).\",\n",
    "  \"shoulder_hip_ankle_collinearity\": \"Distanza normalizzata dell’anca dalla linea spalla-caviglia (plank line error).\",\n",
    "  \"arm_symmetry\": \"Differenza gradi gomito L-R (simmetria braccia).\",\n",
    "  \"leg_symmetry\": \"Differenza gradi ginocchia L-R (simmetria gambe).\",\n",
    "  \"stance_width\": \"Distanza orizzontale tra caviglie (px).\",\n",
    "  \"grip_width\": \"Distanza orizzontale tra polsi (px).\",\n",
    "  \"bar_vertical_disp\": \"ROM verticale mani vs spalle (px). >0 in press; <0 in trazione.\",\n",
    "  \"shoulderY\": \"Quota verticale media spalle (px, origine in alto).\",\n",
    "  \"wristY\": \"Quota verticale media polsi (px, origine in alto).\",\n",
    "  \"knee_to_chest_norm_L\": \"Distanza ginocchio-sx → torace (spalle) normalizzata (MC): più piccola = più vicino.\",\n",
    "  \"knee_to_chest_norm_R\": \"Distanza ginocchio-dx → torace normalizzata.\",\n",
    "  \"crossbody_knee_wrist_prox_L\": \"Distanza ginocchio-sx ↔ polso-dx normalizzata (MC cross).\",\n",
    "  \"crossbody_knee_wrist_prox_R\": \"Distanza ginocchio-dx ↔ polso-sx normalizzata.\",\n",
    "  \"hands_to_feet_min_dist\": \"Distanza minima mano-piede normalizzata (burpee tuck/raccolta).\",\n",
    "  \"tuck_compactness\": \"Compattamento tuck (min distanza ginocchio→torace normalizzata).\",\n",
    "  \"arms_overhead\": \"1 se i polsi stanno sopra le spalle (salto mani in alto), altrimenti 0.\"\n",
    "}"
   ],
   "id": "a0c9fb6b3994acee",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T13:59:33.958636Z",
     "start_time": "2025-09-08T13:59:33.954566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json, requests, os\n",
    "\n",
    "# Se non l'hai già definito:\n",
    "OLLAMA_URL = os.environ.get(\"OLLAMA_URL\", \"http://localhost:11434/api/generate\")\n",
    "OLLAMA_MODEL = os.environ.get(\"OLLAMA_MODEL\", \"llama3.1\")\n",
    "\n",
    "LLM_JUDGE_SYSTEM = \"\"\"Sei un coach di fitness AI. Valuti un singolo frame di un esercizio usando SOLO le feature numeriche fornite.\n",
    "NON inventare ciò che non è nelle feature. Rispondi SOLO JSON con lo schema:\n",
    "{\n",
    "  \"verdict\": \"correct\" | \"minor_issue\" | \"major_issue\",\n",
    "  \"issue_tags\": string[],        // es. [\"depth_short\",\"valgus\"]\n",
    "  \"cues\": string[],              // max 3 correzioni brevi, in italiano\n",
    "  \"confidence\": number,          // 0..1\n",
    "  \"notes\": string                // opzionale (breve)\n",
    "}\n",
    "Linee guida:\n",
    "- Se le misure sono incomplete/ambigue, usa 'minor_issue' e spiega brevemente in 'notes'.\n",
    "- Le 'cues' devono essere concrete e azionabili (es. “Spingi le ginocchia verso l’esterno”).\n",
    "\"\"\"\n",
    "\n",
    "def build_llm_judge_prompt(exercise_name:str, camera_view:str, profile:dict,\n",
    "                           features:dict, feature_docs:dict, mode:str=\"reps\") -> str:\n",
    "    payload = {\n",
    "        \"exercise\": exercise_name,\n",
    "        \"mode\": mode,                      # \"reps\" | \"time\"\n",
    "        \"camera_view\": camera_view,        # \"frontal\" | \"lateral\" | \"45deg\"\n",
    "        \"user_level\": profile.get(\"level\",\"intermediate\"),\n",
    "        \"goals\": profile.get(\"goals\", []),\n",
    "        \"tone\": profile.get(\"preferences\",{}).get(\"tone\",\"motivational_friendly\"),\n",
    "        \"feature_docs\": feature_docs,      # definizioni (glossario)\n",
    "        \"features\": features               # valori istantanei\n",
    "    }\n",
    "    return f\"{LLM_JUDGE_SYSTEM}\\nDati:\\n{json.dumps(payload, ensure_ascii=False)}\\nRispondi SOLO JSON.\"\n",
    "\n",
    "def ollama_json(prompt:str, model:str=OLLAMA_MODEL, temperature:float=0.2, timeout:int=20) -> dict:\n",
    "    try:\n",
    "        r = requests.post(OLLAMA_URL, json={\n",
    "            \"model\": model, \"prompt\": prompt, \"stream\": False, \"options\":{\"temperature\": temperature}\n",
    "        }, timeout=timeout)\n",
    "        r.raise_for_status()\n",
    "        txt = r.json().get(\"response\",\"\").strip()\n",
    "        return json.loads(txt)\n",
    "    except Exception as e:\n",
    "        return {\"_error\": str(e)}\n"
   ],
   "id": "356b218b90fadca2",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T14:00:15.003502Z",
     "start_time": "2025-09-08T14:00:14.997923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def llm_judge_one_frame(image_path:str, exercise_name:str, camera_view:str=\"frontal\",\n",
    "                        profile:dict=None, draw_overlay:bool=True):\n",
    "    import cv2, numpy as np\n",
    "\n",
    "    if profile is None:\n",
    "        profile = {\n",
    "            \"level\": \"intermediate\",\n",
    "            \"goals\": [\"ricomposizione corporea\"],\n",
    "            \"preferences\": {\"tone\":\"motivational_friendly\"}\n",
    "        }\n",
    "\n",
    "    # 1) carica immagine\n",
    "    img = cv2.imread(image_path)\n",
    "    assert img is not None, f\"Immagine non trovata: {image_path}\"\n",
    "\n",
    "    # 2) keypoints & features\n",
    "    pe = PoseEstimator(static_image_mode=True)\n",
    "    res = pe.process(img)\n",
    "    if not (res and res.pose_landmarks):\n",
    "        print(\"❌ Nessun corpo rilevato. Prova con un’immagine a figura intera e ben illuminata.\")\n",
    "        return None\n",
    "\n",
    "    feats = compute_features(res.pose_landmarks, img.shape)\n",
    "\n",
    "    # 3) prepara prompt e chiama LLM\n",
    "    prompt = build_llm_judge_prompt(exercise_name, camera_view, profile, feats, FEATURE_DOCS, mode=\"reps\")\n",
    "    judge = ollama_json(prompt)\n",
    "\n",
    "    # 4) overlay semplice\n",
    "    out = pe.draw_landmarks(img, res.pose_landmarks)\n",
    "    y = 28\n",
    "    header = f\"Exercise: {exercise_name} | View: {camera_view}\"\n",
    "    cv2.putText(out, header, (20,y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (20,220,20), 2); y += 30\n",
    "\n",
    "    if isinstance(judge, dict) and \"_error\" not in judge:\n",
    "        verdict = judge.get(\"verdict\",\"?\")\n",
    "        conf = judge.get(\"confidence\", None)\n",
    "        cues = judge.get(\"cues\", [])[:3]\n",
    "        issues = judge.get(\"issue_tags\", [])[:3]\n",
    "        line1 = f\"Verdict: {verdict}\" + (f\"  (conf {conf:.2f})\" if isinstance(conf,(int,float)) else \"\")\n",
    "        cv2.putText(out, line1, (20,y), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255,180,30), 2); y += 26\n",
    "        if issues:\n",
    "            cv2.putText(out, \"Issues: \" + \", \".join(issues), (20,y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (50,200,255), 2); y += 24\n",
    "        for c in cues:\n",
    "            cv2.putText(out, f\"• {c}\", (20,y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (50,200,255), 2); y += 24\n",
    "    else:\n",
    "        cv2.putText(out, f\"LLM error: {judge.get('_error','?')}\", (20,y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "    # 5) salva risultato\n",
    "    out_path = \"llm_judge_overlay.jpg\"\n",
    "    cv2.imwrite(out_path, out)\n",
    "    print(\"✅ Giudizio LLM:\", json.dumps(judge, ensure_ascii=False))\n",
    "    print(\"Overlay salvato in:\", out_path)\n",
    "    return judge\n"
   ],
   "id": "2a0c7585f1d86459",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T14:01:12.549906Z",
     "start_time": "2025-09-08T14:01:08.698030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Esempi (usa un’immagine coerente col gesto):\n",
    "llm_judge_one_frame(\"../data/image/squat.jpg\", exercise_name=\"goblet_squat\", camera_view=\"frontal\")\n",
    "# llm_judge_one_frame(\"frame_pushup.jpg\", exercise_name=\"push_up\", camera_view=\"lateral\")\n",
    "# llm_judge_one_frame(\"frame_plank.jpg\", exercise_name=\"plank\", camera_view=\"lateral\")\n"
   ],
   "id": "a67f3aabede8cbe0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1757340068.707136 6326649 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M4 Max\n",
      "W0000 00:00:1757340068.754198 6636465 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1757340068.761636 6636465 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Giudizio LLM: {\"verdict\": \"minor_issue\", \"issue_tags\": [\"valgus_flag\"], \"cues\": [\"Assicurati che le ginocchia non collassino verso il centro\", \"Spingi le ginocchie verso l'esterno\"], \"confidence\": 0.8, \"notes\": \"Misura ambigua per la valgus flag, ma sembra che ci sia un leggero collasso delle ginocchia\"}\n",
      "Overlay salvato in: llm_judge_overlay.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'verdict': 'minor_issue',\n",
       " 'issue_tags': ['valgus_flag'],\n",
       " 'cues': ['Assicurati che le ginocchia non collassino verso il centro',\n",
       "  \"Spingi le ginocchie verso l'esterno\"],\n",
       " 'confidence': 0.8,\n",
       " 'notes': 'Misura ambigua per la valgus flag, ma sembra che ci sia un leggero collasso delle ginocchia'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d8173b6510848418"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dc6170954112fd56"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8a191982dd21fb74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- Cell 5: prompts ---\n",
    "\n",
    "SYSTEM_PLAN = \"\"\"Sei un personal trainer AI. Parla e pensa in italiano.\n",
    "Riceverai un profilo utente e l'attrezzatura disponibile. Genera un PIANO SEGRETO di allenamento adatto a livello e obiettivi.\n",
    "NON rivelare l'intero piano all'utente: fornisci solo JSON col piano interno.\n",
    "Il piano deve includere per ciascun esercizio i TARGET TECNICI (soglie angoli/criteri).\n",
    "Rispondi SOLO JSON con lo schema:\n",
    "\n",
    "{\n",
    "  \"plan_id\": \"string\",\n",
    "  \"blocks\": [\n",
    "    {\n",
    "      \"id\": \"B1\",\n",
    "      \"type\": \"warmup|strength|conditioning|finisher\",\n",
    "      \"duration_s\": 300,\n",
    "      \"sequence\": [\n",
    "        {\n",
    "          \"exercise\": \"goblet_squat\",\n",
    "          \"equipment\": [\"dumbbells\"],\n",
    "          \"mode\": \"reps|time\",\n",
    "          \"target\": {\"reps\": 12, \"sets\": 3, \"tempo\": \"3010\", \"rest_s\": 60} or {\"time_s\": 40, \"rounds\": 6, \"rest_s\": 20},\n",
    "          \"technique\": {\n",
    "            \"vars\": {\"knee_top\":160, \"knee_bottom\":100},   // soglie personalizzate\n",
    "            \"transitions\": [\n",
    "              {\"from\":\"top\",\"to\":\"down\",\"when_all\":[\"knee_ang < knee_top\"]},\n",
    "              {\"from\":\"down\",\"to\":\"bottom\",\"when_all\":[\"knee_ang <= knee_bottom\"]},\n",
    "              {\"from\":\"bottom\",\"to\":\"up\",\"when_all\":[\"knee_ang > 120\"]},\n",
    "              {\"from\":\"up\",\"to\":\"top\",\"when_all\":[\"knee_ang >= 160\"], \"rep_complete\": true}\n",
    "            ],\n",
    "            \"errors\": [\n",
    "              {\"when_all\":[\"depth < -10\"], \"message\":\"Scendi un po’ di più\", \"penalty\":0.3},\n",
    "              {\"when_all\":[\"valgus == 1\"], \"message\":\"Ginocchia verso l’esterno\", \"penalty\":0.3}\n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_RUNTIME = \"\"\"Sei un coach AI in diretta (italiano). Ricevi telemetria e stato del piano.\n",
    "Devi: motivare, dare correzioni tecniche brevi, gestire tempi/recuperi, e decidere se progredire/regredire o cambiare esercizio/bocco.\n",
    "Rispondi SOLO JSON con schema:\n",
    "{\n",
    "  \"coach_action\": \"say\" | \"cue\" | \"progress\" | \"rest\" | \"switch_exercise\",\n",
    "  \"message\": \"frase breve in italiano, tono coerente\",\n",
    "  \"adjustments\": {\n",
    "    \"change_tempo\": \"string|optional\",\n",
    "    \"change_target\": {\"reps\": int|optional, \"time_s\": int|optional},\n",
    "    \"switch_to\": {\"block_id\":\"B2\",\"exercise\":\"push_up_knees\"|null}\n",
    "  }\n",
    "}\n",
    "Mantieni frasi brevi, specifiche, non ripetitive. Se errori si ripetono, proponi regressione intelligente.\n",
    "\"\"\"\n",
    "\n",
    "def build_plan_prompt(profile:Dict)->str:\n",
    "    return f\"\"\"{SYSTEM_PLAN}\n",
    "Utente:\n",
    "{json.dumps({\"profile\":profile}, ensure_ascii=False)}\"\"\"\n",
    "\n",
    "def build_runtime_prompt(plan_state:Dict, telemetry:Dict, profile:Dict)->str:\n",
    "    user = {\n",
    "        \"profile\": {\"level\": profile[\"level\"], \"goals\": profile[\"goals\"], \"preferences\": profile[\"preferences\"]},\n",
    "        \"plan_state\": plan_state,\n",
    "        \"telemetry\": telemetry\n",
    "    }\n",
    "    return f\"\"\"{SYSTEM_RUNTIME}\n",
    "Dati:\n",
    "{json.dumps(user, ensure_ascii=False)}\n",
    "Ricorda: SOLO JSON.\"\"\"\n"
   ],
   "id": "1f266006926df1a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- Cell 6: Session Orchestrator ---\n",
    "class SessionOrchestrator:\n",
    "    def __init__(self, profile:Dict):\n",
    "        self.profile = profile\n",
    "        self.pose = PoseEstimator(static_image_mode=False)\n",
    "        self.plan = None             # piano segreto (JSON LLM)\n",
    "        self.detectors: Dict[str, DeclarativeDetector] = {}\n",
    "        self.current_block_idx = 0\n",
    "        self.current_seq_idx = 0\n",
    "        self.block_start_ts = None\n",
    "        self.last_llm_ts = 0.0\n",
    "        self.llm_period = 2.0        # puoi alzare a 3-5s\n",
    "        self.last_llm_msg = None\n",
    "        self.exercise_start_ts = None\n",
    "\n",
    "    # ----- Plan generation -----\n",
    "    def generate_plan(self):\n",
    "        prompt = build_plan_prompt(self.profile)\n",
    "        plan = ollama_json(prompt)\n",
    "        self.plan = plan\n",
    "        self._compile_detectors_from_plan()\n",
    "\n",
    "        self.current_block_idx = 0\n",
    "        self.current_seq_idx = 0\n",
    "        self.block_start_ts = time.time()\n",
    "        self.exercise_start_ts = time.time()\n",
    "\n",
    "    def _compile_detectors_from_plan(self):\n",
    "        self.detectors.clear()\n",
    "        if not self.plan or \"_error\" in self.plan: return\n",
    "        for block in self.plan.get(\"blocks\", []):\n",
    "            for item in block.get(\"sequence\", []):\n",
    "                name = item[\"exercise\"]\n",
    "                tech = item[\"technique\"]\n",
    "                spec = {\n",
    "                    \"name\": name,\n",
    "                    \"initial_phase\": tech.get(\"initial_phase\",\"top\"),\n",
    "                    \"vars\": tech.get(\"vars\",{}),\n",
    "                    \"transitions\": tech.get(\"transitions\",[]),\n",
    "                    \"errors\": tech.get(\"errors\",[])\n",
    "                }\n",
    "                self.detectors[name] = DeclarativeDetector(spec)\n",
    "\n",
    "    # ----- Helpers stato corrente -----\n",
    "    def _current_item(self) -> Optional[Dict]:\n",
    "        if not self.plan or \"_error\" in self.plan: return None\n",
    "        blocks = self.plan.get(\"blocks\", [])\n",
    "        if self.current_block_idx >= len(blocks): return None\n",
    "        seq = blocks[self.current_block_idx].get(\"sequence\", [])\n",
    "        if self.current_seq_idx >= len(seq): return None\n",
    "        return seq[self.current_seq_idx]\n",
    "\n",
    "    def _advance_sequence(self):\n",
    "        item = self._current_item()\n",
    "        if not item: return\n",
    "        self.current_seq_idx += 1\n",
    "        self.exercise_start_ts = time.time()\n",
    "        # reset detector stato\n",
    "        ex = item[\"exercise\"]\n",
    "        if ex in self.detectors: self.detectors[ex].reset()\n",
    "\n",
    "    def _advance_block(self):\n",
    "        self.current_block_idx += 1\n",
    "        self.current_seq_idx = 0\n",
    "        self.block_start_ts = time.time()\n",
    "\n",
    "    # ----- Main tick per frame -----\n",
    "    def process_frame(self, frame_bgr):\n",
    "        res = self.pose.process(frame_bgr)\n",
    "        landmarks = res.pose_landmarks if res and res.pose_landmarks else None\n",
    "        feats = compute_features(landmarks, frame_bgr.shape)\n",
    "\n",
    "        item = self._current_item()\n",
    "        if not item:\n",
    "            out = frame_bgr.copy()\n",
    "            cv2.putText(out, \"Sessione completata. Ottimo lavoro!\", (20,40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,180), 2)\n",
    "            return out, {\"done\": True, \"llm\": self.last_llm_msg}\n",
    "\n",
    "        ex_name = item[\"exercise\"]\n",
    "        det = self.detectors.get(ex_name)\n",
    "        rep_event, diag = det.update(landmarks, frame_bgr.shape) if det else (None, {\"notes\":[]})\n",
    "\n",
    "        # criteri di avanzamento locali (esempi semplici)\n",
    "        mode = item.get(\"mode\",\"reps\")\n",
    "        target = item.get(\"target\",{})\n",
    "        reps_target = target.get(\"reps\")\n",
    "        time_target = target.get(\"time_s\")\n",
    "        rounds = target.get(\"rounds\")\n",
    "        rest_s = target.get(\"rest_s\", 30)\n",
    "        now = time.time()\n",
    "        elapsed_ex = int(now - (self.exercise_start_ts or now))\n",
    "\n",
    "        # invio telemetria al LLM a cadenza o su rep\n",
    "        llm_msg = None\n",
    "        if (now - self.last_llm_ts) > self.llm_period or rep_event is not None:\n",
    "            telemetry = {\n",
    "                \"time_s\": elapsed_ex,\n",
    "                \"exercise\": ex_name,\n",
    "                \"rep\": det.rep if det else 0,\n",
    "                \"last_rep_quality\": getattr(rep_event,\"quality\", None) if rep_event else None,\n",
    "                \"errors_recent\": diag.get(\"notes\",[])[:3],\n",
    "                \"features\": {k:v for k,v in feats.items() if isinstance(v,(int,float))}\n",
    "            }\n",
    "            plan_state = {\n",
    "                \"block_idx\": self.current_block_idx,\n",
    "                \"seq_idx\": self.current_seq_idx,\n",
    "                \"item_target\": target\n",
    "            }\n",
    "            prompt = build_runtime_prompt(plan_state, telemetry, self.profile)\n",
    "            llm_msg = ollama_json(prompt)\n",
    "            self.last_llm_ts = now\n",
    "            if \"adjustments\" in llm_msg:\n",
    "                adj = llm_msg[\"adjustments\"] or {}\n",
    "                if \"change_target\" in adj and isinstance(adj[\"change_target\"], dict):\n",
    "                    target.update({k:v for k,v in adj[\"change_target\"].items() if v is not None})\n",
    "                if \"change_tempo\" in adj and adj[\"change_tempo\"]:\n",
    "                    target[\"tempo\"] = adj[\"change_tempo\"]\n",
    "                if \"switch_to\" in adj and adj[\"switch_to\"]:\n",
    "                    # salto diretto se richiesto\n",
    "                    for bi, block in enumerate(self.plan.get(\"blocks\",[])):\n",
    "                        if block[\"id\"] == adj[\"switch_to\"].get(\"block_id\"):\n",
    "                            self.current_block_idx = bi\n",
    "                            # trova seq con exercise richiesto\n",
    "                            for si, it in enumerate(block.get(\"sequence\",[])):\n",
    "                                if it[\"exercise\"] == adj[\"switch_to\"].get(\"exercise\"):\n",
    "                                    self.current_seq_idx = si\n",
    "                                    break\n",
    "                            self.block_start_ts = now\n",
    "                            self.exercise_start_ts = now\n",
    "                            break\n",
    "            self.last_llm_msg = llm_msg\n",
    "\n",
    "            # se il LLM aggiorna anche le soglie tecniche, ricarica il detector\n",
    "            # (il messaggio potrebbe includere \"technique_update\": {...})\n",
    "            if isinstance(llm_msg, dict) and \"technique_update\" in llm_msg:\n",
    "                upd = llm_msg[\"technique_update\"]\n",
    "                if isinstance(upd, dict) and ex_name in self.detectors:\n",
    "                    spec = self.detectors[ex_name].spec\n",
    "                    spec[\"vars\"] = {**spec.get(\"vars\",{}), **upd.get(\"vars\",{})}\n",
    "                    if \"transitions\" in upd: spec[\"transitions\"] = upd[\"transitions\"]\n",
    "                    if \"errors\" in upd: spec[\"errors\"] = upd[\"errors\"]\n",
    "                    self.detectors[ex_name].load_spec(spec)\n",
    "\n",
    "        # avanzamento locale semplice (puoi rifinirlo con piano: serie/round)\n",
    "        finished = False\n",
    "        if mode == \"reps\" and reps_target is not None and det and det.rep >= reps_target:\n",
    "            finished = True\n",
    "        if mode == \"time\" and time_target is not None and elapsed_ex >= time_target:\n",
    "            finished = True\n",
    "\n",
    "        if finished:\n",
    "            # breve fase di \"rest\" gestita dal LLM\n",
    "            self._advance_sequence()\n",
    "            # se il block finisce\n",
    "            blk = self.plan[\"blocks\"][self.current_block_idx] if self.current_block_idx < len(self.plan[\"blocks\"]) else None\n",
    "            if blk and self.current_seq_idx >= len(blk.get(\"sequence\",[])):\n",
    "                self._advance_block()\n",
    "\n",
    "        # overlay\n",
    "        out = frame_bgr.copy()\n",
    "        out = self.pose.draw_landmarks(out, res.pose_landmarks if res else None)\n",
    "        y=28\n",
    "        for line in [\n",
    "            f\"Block: {self.current_block_idx+1}/{len(self.plan.get('blocks',[])) if self.plan else 0}\",\n",
    "            f\"Exercise: {ex_name}\",\n",
    "            f\"Reps: {det.rep if det else 0}\",\n",
    "            f\"Elapsed: {elapsed_ex}s\"\n",
    "        ]:\n",
    "            cv2.putText(out, line, (20,y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (20,220,20), 2); y+=28\n",
    "\n",
    "        for c in (diag.get(\"notes\",[])[:2] if diag else []):\n",
    "            cv2.putText(out, f\"• {c}\", (20,y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (50,200,255), 2); y+=26\n",
    "\n",
    "        if isinstance(self.last_llm_msg, dict) and self.last_llm_msg.get(\"message\"):\n",
    "            cv2.putText(out, self.last_llm_msg[\"message\"], (20,y+10), cv2.FONT_HERSHEY_SIMPLEX, 0.75, (255,180,30), 2)\n",
    "\n",
    "        if DISPLAY_SCALE != 1.0:\n",
    "            out = cv2.resize(out, None, fx=DISPLAY_SCALE, fy=DISPLAY_SCALE)\n",
    "        return out, {\"diag\": diag, \"llm\": self.last_llm_msg}\n"
   ],
   "id": "8d1b80f843e2436a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- Cell 7: quick tests without camera ---\n",
    "def test_generate_plan_and_one_image(img_path:str):\n",
    "    img = cv2.imread(img_path); assert img is not None, f\"Immagine non trovata: {img_path}\"\n",
    "    eng = SessionOrchestrator(user_profile)\n",
    "    eng.generate_plan()  # chiama LLM per creare piano segreto\n",
    "    frame_out, info = eng.process_frame(img)  # un singolo tick\n",
    "    cv2.imwrite(\"debug_output.jpg\", frame_out)\n",
    "    print(\"LLM last:\", info.get(\"llm\"))\n",
    "    print(\"Saved overlay to debug_output.jpg\")\n",
    "\n",
    "import glob\n",
    "def test_folder(folder_glob:str, delay_ms:int=150):\n",
    "    paths = sorted(glob.glob(folder_glob)); assert paths, f\"Nessun file per {folder_glob}\"\n",
    "    eng = SessionOrchestrator(user_profile); eng.generate_plan()\n",
    "    for p in paths:\n",
    "        img = cv2.imread(p);\n",
    "        if img is None: continue\n",
    "        out, info = eng.process_frame(img)\n",
    "        cv2.imshow(\"AI Trainer (sim)\", out)\n",
    "        key = cv2.waitKey(delay_ms) & 0xFF\n",
    "        if key == 27: break\n",
    "    cv2.destroyAllWindows()\n"
   ],
   "id": "3e573ce66c930be4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
